# Cap√≠tulo 2: Conectando ao Cluster EMR

## Introdu√ß√£o

Ap√≥s criar seu cluster EMR na AWS, o pr√≥ximo passo √© estabelecer uma conex√£o com ele para executar comandos, monitorar recursos e submeter trabalhos. Neste cap√≠tulo, voc√™ aprender√° como acessar o cluster via SSH a partir de diferentes sistemas operacionais e executar comandos b√°sicos para verificar o estado do cluster.

## Pr√©-requisitos

Antes de come√ßar, voc√™ precisar√°:

- Um cluster EMR em execu√ß√£o (status "Aguardando")
- O arquivo de chave privada (.pem) usado na cria√ß√£o do cluster
- O DNS p√∫blico do n√≥ master do cluster
- Um terminal (Linux/macOS) ou cliente SSH (Windows)

## Gloss√°rio para Iniciantes üìù

- **SSH**: Secure Shell, protocolo para acesso remoto seguro a servidores
- **Terminal**: Interface de linha de comando para executar comandos
- **N√≥ Master**: Servidor principal que coordena o trabalho no cluster EMR
- **YARN**: Yet Another Resource Negotiator, gerenciador de recursos do Hadoop
- **Spark-shell**: Interface interativa para testar comandos Spark
- **HDFS**: Hadoop Distributed File System, sistema de arquivos distribu√≠do

## Conectando ao Cluster via SSH

### Para usu√°rios Linux e macOS

1. Abra o terminal
2. Use o comando SSH com o arquivo de chave privada:

```bash
ssh -i /caminho/para/MeuParDeChaves.pem hadoop@ec2-xx-xx-xx-xx.compute-1.amazonaws.com
```


‚û°Ô∏è Digite o comando SSH substituindo o caminho da chave e o endere√ßo DNS do n√≥ master.

üí° **Dica**: Substitua `/caminho/para/MeuParDeChaves.pem` pelo caminho completo para o seu arquivo .pem e `ec2-xx-xx-xx-xx.compute-1.amazonaws.com` pelo DNS p√∫blico do seu n√≥ master.

3. Na primeira conex√£o, voc√™ receber√° um aviso sobre a autenticidade do host. Digite "yes" para continuar.


‚û°Ô∏è Digite "yes" quando solicitado para adicionar o host √† lista de hosts conhecidos.

4. Se a conex√£o for bem-sucedida, voc√™ ver√° o prompt do EMR:

```
       __|  __|_  )
       _|  (     /   Amazon Linux 2 AMI
      ___|\___|___|

https://aws.amazon.com/amazon-linux-2/
```

### Para usu√°rios Windows

#### Op√ß√£o 1: Usando PuTTY

1. Converta o arquivo .pem para o formato .ppk usando PuTTYgen:
   - Abra PuTTYgen
   - Clique em "Load" e selecione seu arquivo .pem
   - Clique em "Save private key" para gerar o arquivo .ppk

‚û°Ô∏è Clique em "Load" para carregar o arquivo .pem e depois em "Save private key" para salvar como .ppk.

2. Configure a conex√£o no PuTTY:
   - No campo "Host Name", digite: `hadoop@ec2-xx-xx-xx-xx.compute-1.amazonaws.com`
   - No menu lateral, navegue at√© Connection > SSH > Auth
   - Em "Private key file for authentication", clique em "Browse" e selecione o arquivo .ppk

‚û°Ô∏è Configure o host e navegue at√© a se√ß√£o de autentica√ß√£o para selecionar o arquivo .ppk.

3. Clique em "Open" para iniciar a conex√£o
4. Clique em "Yes" no alerta de seguran√ßa

#### Op√ß√£o 2: Usando Windows Subsystem for Linux (WSL)

Se voc√™ tiver o WSL instalado, pode seguir as mesmas instru√ß√µes para Linux:

```bash
ssh -i /caminho/para/MeuParDeChaves.pem hadoop@ec2-xx-xx-xx-xx.compute-1.amazonaws.com
```

#### Op√ß√£o 3: Usando Windows Terminal com OpenSSH

Windows 10 e 11 incluem o cliente OpenSSH:

```powershell
ssh -i C:\caminho\para\MeuParDeChaves.pem hadoop@ec2-xx-xx-xx-xx.compute-1.amazonaws.com
```

üí° **Dica**: No Windows, voc√™ pode precisar ajustar as permiss√µes do arquivo .pem. No PowerShell, use:

```powershell
icacls.exe "C:\caminho\para\MeuParDeChaves.pem" /inheritance:r /grant:r "$($env:USERNAME):(R)"
```

## Comandos √öteis para Navega√ß√£o e Verifica√ß√£o

Ap√≥s conectar-se ao n√≥ master, voc√™ pode executar diversos comandos para explorar o cluster:

### Verificar a vers√£o do Hadoop

```bash
hadoop version
```

Exemplo de sa√≠da:
```
Hadoop 3.3.3
Source code repository https://github.com/apache/hadoop.git -r 6d7be4fb8b4c0c1d499c9f8e3c1503b58a6922d2
Compiled by ubuntu on 2022-08-02T07:01Z
Compiled with protoc 3.14.0
From source with checksum fb9dd8918a7b8a5b430d61af249f359
```

### Verificar a vers√£o do Spark

```bash
spark-submit --version
```

Exemplo de sa√≠da:
```
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 3.3.1
      /_/
                        
Using Scala version 2.12.15, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_332
```

### Listar os n√≥s do cluster

```bash
yarn node -list
```

Exemplo de sa√≠da:
```
Total Nodes:3
         Node-Id             Node-State Node-Http-Address       Number-of-Running-Containers
ip-172-31-28-254.ec2.internal           RUNNING ip-172-31-28-254.ec2.internal:8042                                  0
ip-172-31-30-169.ec2.internal           RUNNING ip-172-31-30-169.ec2.internal:8042                                  0
ip-172-31-25-107.ec2.internal           RUNNING ip-172-31-25-107.ec2.internal:8042                                  0
```

### Verificar o status dos aplicativos YARN

```bash
yarn application -list
```

Exemplo de sa√≠da (quando n√£o h√° aplicativos em execu√ß√£o):
```
Total number of applications (application-types: [] and states: [SUBMITTED, ACCEPTED, RUNNING]):0
```

### Verificar o espa√ßo em disco

```bash
df -h
```

Exemplo de sa√≠da:
```
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs        7.6G     0  7.6G   0% /dev
tmpfs           7.6G     0  7.6G   0% /dev/shm
tmpfs           7.6G  464K  7.6G   1% /run
tmpfs           7.6G     0  7.6G   0% /sys/fs/cgroup
/dev/xvda1       50G  8.4G   42G  17% /
/dev/xvdb      1014G   77M  964G   1% /mnt/s3
tmpfs           1.6G     0  1.6G   0% /run/user/1001
```

### Verificar a mem√≥ria dispon√≠vel

```bash
free -h
```

Exemplo de sa√≠da:
```
              total        used        free      shared  buff/cache   available
Mem:            15G        1.2G         12G        464K        1.8G         13G
Swap:            0B          0B          0B
```

### Verificar os processos em execu√ß√£o

```bash
ps aux | grep spark
```

### Navegar pelo sistema de arquivos HDFS

```bash
# Listar diret√≥rios no HDFS
hdfs dfs -ls /

# Criar um diret√≥rio no HDFS
hdfs dfs -mkdir /user/hadoop/teste

# Verificar espa√ßo dispon√≠vel no HDFS
hdfs dfs -df -h
```

## Testando o Spark Localmente via Spark-Shell

O Spark-Shell √© uma interface interativa que permite testar comandos Spark em tempo real. √â uma excelente ferramenta para aprendizado e depura√ß√£o.

### Iniciando o Spark-Shell

```bash
spark-shell
```


‚û°Ô∏è Execute o comando spark-shell e aguarde o carregamento da interface interativa.

Voc√™ ver√° uma interface Scala com o prompt `scala>`. Isso indica que o Spark-Shell est√° pronto para receber comandos.

### Exemplos B√°sicos no Spark-Shell

#### Criando um RDD (Resilient Distributed Dataset)

```scala
val data = Array(1, 2, 3, 4, 5)
val distData = sc.parallelize(data)
```

#### Contando elementos

```scala
distData.count()
```

Sa√≠da esperada:
```
res0: Long = 5
```

#### Somando elementos

```scala
distData.reduce((a, b) => a + b)
```

Sa√≠da esperada:
```
res1: Int = 15
```

#### Criando um DataFrame

```scala
val df = spark.createDataFrame(Seq(
  (1, "Jo√£o", 25),
  (2, "Maria", 30),
  (3, "Pedro", 35)
)).toDF("id", "nome", "idade")

df.show()
```

Sa√≠da esperada:
```
+---+-----+-----+
| id| nome|idade|
+---+-----+-----+
|  1| Jo√£o|   25|
|  2|Maria|   30|
|  3|Pedro|   35|
+---+-----+-----+
```

#### Filtrando dados

```scala
df.filter($"idade" > 30).show()
```

Sa√≠da esperada:
```
+---+-----+-----+
| id| nome|idade|
+---+-----+-----+
|  3|Pedro|   35|
+---+-----+-----+
```

#### Lendo um arquivo CSV (se dispon√≠vel)

```scala
// Substitua pelo caminho real do seu arquivo
val csvDF = spark.read.option("header", "true").csv("s3://meu-bucket/dados/exemplo.csv")
csvDF.show(5)
```

### Saindo do Spark-Shell

Para sair do Spark-Shell, pressione `Ctrl+D` ou digite `:quit`.

## Usando PySpark Shell

Se voc√™ preferir Python ao inv√©s de Scala, pode usar o PySpark Shell:

```bash
pyspark
```


‚û°Ô∏è Execute o comando pyspark e aguarde o carregamento da interface interativa Python.

### Exemplos B√°sicos no PySpark

#### Criando um RDD

```python
data = [1, 2, 3, 4, 5]
distData = sc.parallelize(data)
```

#### Contando elementos

```python
distData.count()
```

Sa√≠da esperada:
```
5
```

#### Somando elementos

```python
distData.reduce(lambda a, b: a + b)
```

Sa√≠da esperada:
```
15
```

#### Criando um DataFrame

```python
from pyspark.sql import Row
df = spark.createDataFrame([
    Row(id=1, nome="Jo√£o", idade=25),
    Row(id=2, nome="Maria", idade=30),
    Row(id=3, nome="Pedro", idade=35)
])

df.show()
```

Sa√≠da esperada:
```
+---+-----+-----+
| id| nome|idade|
+---+-----+-----+
|  1| Jo√£o|   25|
|  2|Maria|   30|
|  3|Pedro|   35|
+---+-----+-----+
```

## Transferindo Arquivos para o Cluster

### Do seu computador local para o cluster

Usando SCP (Secure Copy Protocol):

```bash
# Para Linux/macOS/Windows com OpenSSH
scp -i /caminho/para/MeuParDeChaves.pem arquivo.py hadoop@ec2-xx-xx-xx-xx.compute-1.amazonaws.com:~/

# Para Windows com PuTTY, use PSCP
pscp -i C:\caminho\para\MeuParDeChaves.ppk C:\caminho\para\arquivo.py hadoop@ec2-xx-xx-xx-xx.compute-1.amazonaws.com:~/
```

### Do cluster para o S3

```bash
# Copiar um arquivo local para o S3
aws s3 cp ~/arquivo.py s3://meu-bucket/scripts/

# Copiar um diret√≥rio inteiro para o S3
aws s3 cp ~/meu-diretorio/ s3://meu-bucket/scripts/ --recursive
```

## Boas Pr√°ticas para Conex√£o SSH üî•

1. **Seguran√ßa**: Nunca compartilhe seu arquivo de chave privada (.pem).

2. **Timeout**: Para evitar desconex√µes por inatividade, configure o cliente SSH para enviar pacotes keep-alive:
   ```bash
   # Adicione ao seu arquivo ~/.ssh/config
   Host *.amazonaws.com
     ServerAliveInterval 60
   ```

3. **T√∫nel SSH**: Para acessar interfaces web do cluster (como o Spark History Server), configure um t√∫nel SSH:
   ```bash
   ssh -i /caminho/para/MeuParDeChaves.pem -N -L 18080:localhost:18080 hadoop@ec2-xx-xx-xx-xx.compute-1.amazonaws.com
   ```
   Depois acesse `http://localhost:18080` no seu navegador.

4. **Aliases**: Crie aliases para comandos frequentes:
   ```bash
   # Adicione ao seu arquivo ~/.bashrc no n√≥ master
   alias hdfs-ls='hdfs dfs -ls'
   alias yarn-apps='yarn application -list'
   ```

5. **Scripts de Inicializa√ß√£o**: Crie scripts para configurar seu ambiente automaticamente ao conectar:
   ```bash
   # Crie um arquivo ~/setup.sh no n√≥ master
   #!/bin/bash
   echo "Configurando ambiente..."
   export SPARK_HOME=/usr/lib/spark
   export PATH=$PATH:$SPARK_HOME/bin
   ```

## Solu√ß√£o de Problemas Comuns

### Erro "Permission denied (publickey)"

Verifique:
- Se est√° usando o arquivo de chave correto
- Se as permiss√µes do arquivo .pem est√£o corretas (chmod 400)
- Se est√° usando o nome de usu√°rio correto (hadoop)

### Conex√£o SSH Lenta

Poss√≠veis solu√ß√µes:
- Desative a verifica√ß√£o DNS no cliente SSH
- Verifique a lat√™ncia de rede para a regi√£o AWS
- Considere usar uma inst√¢ncia bastion na mesma regi√£o

### Erro "Host key verification failed"

Se voc√™ recriou o cluster com o mesmo DNS:
```bash
ssh-keygen -R ec2-xx-xx-xx-xx.compute-1.amazonaws.com
```

## Conclus√£o

Neste cap√≠tulo, voc√™ aprendeu como conectar ao seu cluster EMR via SSH a partir de diferentes sistemas operacionais, executar comandos b√°sicos para verificar o estado do cluster e testar o Spark localmente usando o Spark-Shell. No pr√≥ximo cap√≠tulo, aprenderemos como submeter c√≥digo Spark para execu√ß√£o no cluster.

---

üîç **Pr√≥ximo Cap√≠tulo**: [Submetendo C√≥digo com Spark-Submit](03_submetendo_codigo_spark_submit.md)
