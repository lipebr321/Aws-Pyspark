# Cap√≠tulo 8: Acessando Logs e Debugando

## Introdu√ß√£o

Quando executamos aplica√ß√µes Spark no EMR, √© comum enfrentarmos problemas que precisam ser diagnosticados e resolvidos. O acesso aos logs e a compreens√£o das t√©cnicas de debugging s√£o essenciais para identificar e corrigir erros, otimizar o desempenho e garantir o funcionamento correto das aplica√ß√µes. Neste cap√≠tulo, voc√™ aprender√° onde encontrar os logs no EMR, como acess√°-los e as melhores pr√°ticas para debugging de aplica√ß√µes Spark.

## Pr√©-requisitos

Antes de come√ßar, voc√™ precisar√°:

- Um cluster EMR em execu√ß√£o
- Aplica√ß√µes Spark executadas no cluster
- Acesso SSH ao n√≥ master do cluster
- Conhecimentos b√°sicos de Spark e YARN

## Gloss√°rio para Iniciantes üìù

- **Log**: Registro cronol√≥gico de eventos ocorridos durante a execu√ß√£o de uma aplica√ß√£o
- **YARN**: Yet Another Resource Negotiator, gerenciador de recursos do Hadoop
- **Container**: Unidade de execu√ß√£o no YARN que encapsula recursos (CPU, mem√≥ria)
- **ApplicationMaster**: Processo YARN que gerencia a aplica√ß√£o no cluster
- **Driver**: Processo principal que coordena a execu√ß√£o da aplica√ß√£o Spark
- **Executor**: Processo que executa as tarefas da aplica√ß√£o Spark
- **Spark History Server**: Interface web para visualizar logs de aplica√ß√µes Spark conclu√≠das
- **stderr/stdout**: Fluxos de sa√≠da padr√£o para erros e sa√≠da normal, respectivamente

## Onde Encontrar Logs no EMR

Os logs no EMR est√£o distribu√≠dos em v√°rios locais, dependendo do tipo de log e do componente relacionado:

### 1. Logs do YARN

O YARN √© o gerenciador de recursos usado pelo Spark no EMR e mant√©m logs detalhados de todas as aplica√ß√µes:

#### Localiza√ß√£o no Sistema de Arquivos

```
/var/log/hadoop-yarn/containers/
/var/log/hadoop-yarn/apps/
```

#### Acesso via Linha de Comando

Para listar aplica√ß√µes YARN:

```bash
yarn application -list
```

üñºÔ∏è **Print do terminal mostrando o resultado do comando yarn application -list**
‚û°Ô∏è Execute o comando para listar as aplica√ß√µes YARN em execu√ß√£o ou conclu√≠das recentemente.

Para ver os logs de uma aplica√ß√£o espec√≠fica:

```bash
yarn logs -applicationId application_1621234567890_0001
```

üí° **Dica**: Voc√™ pode filtrar os logs por tipo usando o par√¢metro `-log_files`:

```bash
# Ver apenas logs do stdout
yarn logs -applicationId application_1621234567890_0001 -log_files stdout

# Ver apenas logs do stderr
yarn logs -applicationId application_1621234567890_0001 -log_files stderr
```

### 2. Logs do Spark

#### Localiza√ß√£o no Sistema de Arquivos

Os logs espec√≠ficos do Spark est√£o dispon√≠veis em:

```
/var/log/spark/
```

Para aplica√ß√µes em execu√ß√£o via YARN, os logs do Spark est√£o dentro dos diret√≥rios de containers do YARN:

```
/var/log/hadoop-yarn/containers/container_1621234567890_0001_01_000001/
```

#### Acesso via Spark History Server

O Spark History Server fornece uma interface web para visualizar logs de aplica√ß√µes conclu√≠das:

```
http://MASTER_DNS:18080
```

Para acessar o Spark History Server, configure um t√∫nel SSH:

```bash
ssh -i /caminho/para/MeuParDeChaves.pem -N -L 18080:localhost:18080 hadoop@ec2-xx-xx-xx-xx.compute-1.amazonaws.com
```

üñºÔ∏è **Print da interface web do Spark History Server**
‚û°Ô∏è Acesse http://localhost:18080 no seu navegador ap√≥s configurar o t√∫nel SSH.

### 3. Logs do EMR

O EMR tamb√©m mant√©m logs espec√≠ficos do servi√ßo:

#### Localiza√ß√£o no Sistema de Arquivos

```
/var/log/aws-emr-service-nanny/
/var/log/bootstrap-actions/
```

#### Logs no S3

Se voc√™ configurou o EMR para armazenar logs no S3 (recomendado), eles estar√£o dispon√≠veis em:

```
s3://meu-bucket-logs-emr/logs/j-XXXXXXXXXXXXXXX/
```

Onde `j-XXXXXXXXXXXXXXX` √© o ID do cluster.

## Como Acessar Arquivos .stderr, .stdout, .log.gz

### Arquivos .stderr e .stdout

Estes arquivos cont√™m a sa√≠da de erro e a sa√≠da padr√£o dos processos, respectivamente:

#### Via SSH

```bash
# Acessar o n√≥ master via SSH
ssh -i /caminho/para/MeuParDeChaves.pem hadoop@ec2-xx-xx-xx-xx.compute-1.amazonaws.com

# Navegar at√© o diret√≥rio de containers
cd /var/log/hadoop-yarn/containers/

# Listar os containers
ls -la

# Encontrar o container espec√≠fico (geralmente o primeiro √© o ApplicationMaster)
cd container_1621234567890_0001_01_000001/

# Ver o conte√∫do dos arquivos de log
cat stdout
cat stderr
```

üñºÔ∏è **Print do terminal mostrando o conte√∫do de um arquivo stderr**
‚û°Ô∏è Execute o comando cat stderr e observe a sa√≠da com mensagens de erro.

#### Via YARN CLI

```bash
yarn logs -applicationId application_1621234567890_0001 -log_files stdout > app_stdout.log
yarn logs -applicationId application_1621234567890_0001 -log_files stderr > app_stderr.log
```

### Arquivos .log.gz

Estes s√£o arquivos de log compactados, comuns para logs mais antigos ou volumosos:

```bash
# Visualizar o conte√∫do sem descompactar
zcat hadoop-yarn-resourcemanager-ip-172-31-25-107.log.gz | less

# Descompactar e salvar
gunzip -c hadoop-yarn-resourcemanager-ip-172-31-25-107.log.gz > resourcemanager.log
```

### Logs no S3

Para acessar logs armazenados no S3:

```bash
# Listar logs dispon√≠veis
aws s3 ls s3://meu-bucket-logs-emr/logs/j-XXXXXXXXXXXXXXX/

# Copiar logs para o sistema de arquivos local
aws s3 cp s3://meu-bucket-logs-emr/logs/j-XXXXXXXXXXXXXXX/containers/application_1621234567890_0001/ ./logs/ --recursive

# Ver um arquivo espec√≠fico
aws s3 cp s3://meu-bucket-logs-emr/logs/j-XXXXXXXXXXXXXXX/containers/application_1621234567890_0001/container_1621234567890_0001_01_000001/stderr - | less
```

## Boas Pr√°ticas para Debugging üî•

### 1. Implementar Logging Adequado

Em aplica√ß√µes Python:

```python
import logging

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)
logger = logging.getLogger(__name__)

# Usar em diferentes n√≠veis
logger.debug("Informa√ß√£o detalhada para debugging")
logger.info("Informa√ß√£o geral sobre o progresso")
logger.warning("Aviso sobre situa√ß√µes inesperadas")
logger.error("Erro que permite continuar a execu√ß√£o")
logger.critical("Erro cr√≠tico que impede a continua√ß√£o")
```

Em aplica√ß√µes Scala:

```scala
import org.apache.log4j.{Logger, Level}

// Configurar logger
val logger = Logger.getLogger(getClass.getName)

// Usar em diferentes n√≠veis
logger.debug("Informa√ß√£o detalhada para debugging")
logger.info("Informa√ß√£o geral sobre o progresso")
logger.warn("Aviso sobre situa√ß√µes inesperadas")
logger.error("Erro que permite continuar a execu√ß√£o")
logger.fatal("Erro cr√≠tico que impede a continua√ß√£o")
```

### 2. Monitorar o Progresso

Adicione logs para monitorar o progresso de opera√ß√µes longas:

```python
# Em Python
total_registros = df.count()
logger.info(f"Total de registros: {total_registros}")

# Processar em batches
for i, batch in enumerate(batches):
    logger.info(f"Processando batch {i+1}/{len(batches)}")
    # Processamento...
    logger.info(f"Batch {i+1} conclu√≠do")
```

### 3. Capturar e Registrar Exce√ß√µes

```python
# Em Python
try:
    # C√≥digo que pode gerar exce√ß√£o
    df = spark.read.csv(input_path)
    # Processamento...
except Exception as e:
    logger.error(f"Erro ao processar dados: {str(e)}")
    # Detalhes adicionais para debugging
    import traceback
    logger.error(traceback.format_exc())
    raise  # Re-lan√ßar a exce√ß√£o ou tratar adequadamente
```

### 4. Usar Checkpoints para Debugging

Salve estados intermedi√°rios para facilitar o debugging:

```python
# Em Python
# Configurar diret√≥rio de checkpoint
spark.sparkContext.setCheckpointDir("s3://meu-bucket/checkpoints")

# Ap√≥s transforma√ß√µes complexas
df_transformado = aplicar_transformacoes_complexas(df)
df_transformado.checkpoint()  # Materializa o DataFrame
df_transformado.cache()       # Mant√©m em mem√≥ria para acesso r√°pido

# Verificar resultado intermedi√°rio
df_transformado.show(5)
```

### 5. Visualizar Plano de Execu√ß√£o

Analise o plano de execu√ß√£o para identificar gargalos:

```python
# Em Python
# Mostrar plano de execu√ß√£o l√≥gico
df_final.explain()

# Mostrar plano de execu√ß√£o f√≠sico detalhado
df_final.explain(True)
```

üñºÔ∏è **Print do terminal mostrando o resultado do comando explain()**
‚û°Ô∏è Execute df_final.explain(True) e observe o plano de execu√ß√£o detalhado.

### 6. Monitorar M√©tricas de Execu√ß√£o

Use a interface web do Spark para monitorar m√©tricas em tempo real:

- **Spark UI**: http://MASTER_DNS:4040 (para aplica√ß√µes em execu√ß√£o)
- **YARN ResourceManager**: http://MASTER_DNS:8088
- **Spark History Server**: http://MASTER_DNS:18080 (para aplica√ß√µes conclu√≠das)

üñºÔ∏è **Print da interface web do Spark UI mostrando m√©tricas de execu√ß√£o**
‚û°Ô∏è Acesse http://localhost:4040 no seu navegador ap√≥s configurar o t√∫nel SSH.

## T√©cnicas Avan√ßadas de Debugging

### 1. Debugging Distribu√≠do

Para depurar problemas espec√≠ficos de n√≥s:

```bash
# Verificar logs de um n√≥ espec√≠fico
yarn logs -applicationId application_1621234567890_0001 -nodeAddress ip-172-31-25-107.ec2.internal:8041
```

### 2. An√°lise de Skew de Dados

Identificar e corrigir skew (distribui√ß√£o desigual) de dados:

```python
# Em Python
# Verificar distribui√ß√£o de parti√ß√µes
partition_counts = df.rdd.glom().map(len).collect()
print(f"Contagem de registros por parti√ß√£o: {partition_counts}")
print(f"Min: {min(partition_counts)}, Max: {max(partition_counts)}, Avg: {sum(partition_counts)/len(partition_counts)}")

# Reparticionar para distribuir melhor os dados
df_rebalanced = df.repartition(100)
```

### 3. Debugging de Problemas de Mem√≥ria

Para identificar e resolver problemas de mem√≥ria:

```bash
# Verificar configura√ß√µes de mem√≥ria
yarn application -status application_1621234567890_0001 | grep memory

# Aumentar mem√≥ria no spark-submit
--executor-memory 8g --driver-memory 4g
```

Ajustar configura√ß√µes de mem√≥ria no c√≥digo:

```python
# Em Python
spark = SparkSession.builder \
    .appName("Minha Aplica√ß√£o") \
    .config("spark.executor.memory", "8g") \
    .config("spark.driver.memory", "4g") \
    .config("spark.memory.fraction", "0.8") \
    .config("spark.memory.storageFraction", "0.3") \
    .getOrCreate()
```

### 4. Debugging de Problemas de Serializa√ß√£o

Para resolver problemas de serializa√ß√£o:

```python
# Em Python
# Usar broadcast para vari√°veis grandes
large_dict = {"key1": "value1", "key2": "value2", ...}
broadcast_dict = spark.sparkContext.broadcast(large_dict)

# Acessar no RDD/DataFrame
def process_with_dict(row):
    dict_value = broadcast_dict.value.get(row.key)
    # Processamento...
    return result

result_df = df.rdd.map(process_with_dict).toDF()
```

## Exemplos Pr√°ticos de Debugging

### Exemplo 1: Identificando e Corrigindo Erros de Transforma√ß√£o

Suponha que voc√™ tenha o seguinte c√≥digo com erro:

```python
# C√≥digo com erro
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, to_date

spark = SparkSession.builder.appName("Debug Example").getOrCreate()

# Ler dados
df = spark.read.csv("s3://meu-bucket/dados/vendas.csv", header=True)

# Transforma√ß√£o com erro
df_processado = df.withColumn("data_formatada", to_date(col("data"), "yyyy-MM-dd"))
df_processado = df_processado.withColumn("valor_total", col("valor") * col("quantidade"))

# Salvar resultados
df_processado.write.parquet("s3://meu-bucket/resultados/vendas_processadas")
```

Ao executar, voc√™ recebe um erro. Vamos depurar:

1. **Verificar o erro nos logs**:

```bash
yarn logs -applicationId application_1621234567890_0001 -log_files stderr
```

Sa√≠da (exemplo):
```
Py4JJavaError: An error occurred while calling o111.withColumn.
: org.apache.spark.sql.AnalysisException: cannot resolve 'quantidade' given input columns: [id, produto, categoria, valor, data];
```

2. **Corrigir o c√≥digo**:

```python
# Verificar schema
df.printSchema()

# Verificar se a coluna existe
print("Colunas dispon√≠veis:", df.columns)

# Corrigir o c√≥digo
if "quantidade" not in df.columns:
    # Adicionar coluna padr√£o ou ajustar a l√≥gica
    df = df.withColumn("quantidade", lit(1))

# Continuar com a transforma√ß√£o
df_processado = df.withColumn("valor_total", col("valor") * col("quantidade"))
```

### Exemplo 2: Debugging de Problemas de Performance

Suponha que voc√™ tenha uma aplica√ß√£o que est√° demorando muito para executar:

1. **Analisar o plano de execu√ß√£o**:

```python
df_final.explain(True)
```

2. **Identificar opera√ß√µes custosas** (como shuffles, joins, etc.)

3. **Otimizar o c√≥digo**:

```python
# Antes: Join custoso
df_joined = df1.join(df2, df1.id == df2.id)

# Depois: Join otimizado com broadcast
from pyspark.sql.functions import broadcast
df_joined = df1.join(broadcast(df2), df1.id == df2.id)

# Persistir DataFrames intermedi√°rios usados m√∫ltiplas vezes
df_intermediario = transformacao_complexa(df)
df_intermediario.cache()

# Reparticionar antes de opera√ß√µes de agrupamento
df_reparticionado = df.repartitionByRange(100, "chave_distribuicao")
```

## Solu√ß√£o de Problemas Comuns

### 1. "Container killed by YARN"

**Sintomas**: Aplica√ß√£o falha com mensagem "Container killed by YARN for exceeding memory limits"

**Solu√ß√µes**:
- Aumentar a mem√≥ria do executor: `--executor-memory 8g`
- Reduzir o paralelismo: `--conf spark.sql.shuffle.partitions=100`
- Otimizar transforma√ß√µes que consomem muita mem√≥ria
- Usar persist√™ncia em disco em vez de mem√≥ria: `.persist(StorageLevel.DISK_ONLY)`

### 2. "Task not serializable"

**Sintomas**: Erro "Task not serializable: java.io.NotSerializableException"

**Solu√ß√µes**:
- Garantir que todas as classes usadas em fun√ß√µes lambda sejam serializ√°veis
- Usar `broadcast` para vari√°veis n√£o serializ√°veis
- Mover a cria√ß√£o de objetos n√£o serializ√°veis para dentro das fun√ß√µes lambda

### 3. "No space left on device"

**Sintomas**: Erro "No space left on device" nos logs

**Solu√ß√µes**:
- Limpar diret√≥rios tempor√°rios: `/tmp`, `/mnt/tmp`
- Configurar o Spark para usar o S3 para shuffle: `spark.shuffle.storage.s3.path`
- Aumentar o tamanho do volume EBS do n√≥ master

### 4. Aplica√ß√£o Lenta

**Sintomas**: A aplica√ß√£o executa, mas √© muito mais lenta do que o esperado

**Solu√ß√µes**:
- Verificar o plano de execu√ß√£o com `explain(True)`
- Identificar e corrigir skew de dados
- Otimizar joins com `broadcast` para tabelas pequenas
- Ajustar o n√∫mero de parti√ß√µes
- Usar formatos de arquivo otimizados (Parquet, ORC)
- Aplicar filtros o mais cedo poss√≠vel no pipeline

## Conclus√£o

Neste cap√≠tulo, voc√™ aprendeu onde encontrar logs no EMR, como acessar arquivos de log em diferentes formatos, e as melhores pr√°ticas para debugging de aplica√ß√µes Spark. A capacidade de diagnosticar e resolver problemas √© essencial para o desenvolvimento e manuten√ß√£o de aplica√ß√µes Spark eficientes e confi√°veis. No pr√≥ximo cap√≠tulo, aprenderemos como verificar os resultados do processamento no S3.

---

üîç **Pr√≥ximo Cap√≠tulo**: [Verificando Resultado no S3](09_verificando_resultado_no_s3.md)
