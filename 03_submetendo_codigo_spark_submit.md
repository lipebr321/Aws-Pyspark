# Cap√≠tulo 3: Submetendo C√≥digo com Spark-Submit

## Introdu√ß√£o

Ap√≥s conectar-se ao cluster EMR, o pr√≥ximo passo √© executar aplica√ß√µes Spark para processar seus dados. O `spark-submit` √© a ferramenta padr√£o para submeter aplica√ß√µes Spark ao cluster, permitindo configurar recursos, depend√™ncias e par√¢metros de execu√ß√£o. Neste cap√≠tulo, voc√™ aprender√° a estrutura b√°sica do comando `spark-submit` e como executar aplica√ß√µes Python que processam dados armazenados no S3.

## Pr√©-requisitos

Antes de come√ßar, voc√™ precisar√°:

- Um cluster EMR em execu√ß√£o
- Acesso SSH ao n√≥ master do cluster
- Conhecimentos b√°sicos de Python e Spark
- Um bucket S3 para armazenar scripts e dados

## Gloss√°rio para Iniciantes üìù

- **Spark-submit**: Ferramenta de linha de comando para executar aplica√ß√µes Spark
- **YARN**: Gerenciador de recursos do Hadoop que aloca recursos para aplica√ß√µes
- **Deploy-mode**: Modo de implanta√ß√£o que define onde o driver da aplica√ß√£o Spark ser√° executado
- **Driver Program**: Processo principal que coordena a execu√ß√£o da aplica√ß√£o Spark
- **Executor**: Processo que executa as tarefas da aplica√ß√£o Spark
- **S3**: Amazon Simple Storage Service, servi√ßo de armazenamento de objetos da AWS
- **Parquet**: Formato colunar de armazenamento otimizado para an√°lise de dados

## Estrutura B√°sica de um Comando Spark-Submit

O comando `spark-submit` possui a seguinte estrutura b√°sica:

```bash
spark-submit \
  --master <master-url> \
  --deploy-mode <deploy-mode> \
  --conf <key>=<value> \
  --class <main-class> \
  --jars <comma-separated-jars> \
  --py-files <comma-separated-python-files> \
  <application-jar-or-python-file> \
  [application-arguments]
```

### Par√¢metros Principais

- `--master`: Define o gerenciador de recursos (yarn, local, spark://host:port)
- `--deploy-mode`: Define o modo de implanta√ß√£o (client ou cluster)
- `--conf`: Define configura√ß√µes espec√≠ficas do Spark
- `--class`: Define a classe principal para aplica√ß√µes Java/Scala
- `--jars`: Lista de JARs adicionais para incluir no classpath
- `--py-files`: Lista de arquivos Python adicionais para incluir no PYTHONPATH
- `<application-jar-or-python-file>`: Caminho para o arquivo JAR ou Python da aplica√ß√£o
- `[application-arguments]`: Argumentos para a aplica√ß√£o

## Exemplo Funcional com Python

Vamos criar um exemplo simples de aplica√ß√£o PySpark que l√™ dados de um arquivo CSV no S3, realiza algumas transforma√ß√µes e salva o resultado em formato Parquet no S3.

### Passo 1: Criar o Script Python

Primeiro, vamos criar um script Python b√°sico para processar dados:

```python
# processador_dados.py
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, year, month, dayofmonth

def main():
    # Inicializar a sess√£o Spark
    spark = SparkSession.builder \
        .appName("Processador de Dados S3") \
        .getOrCreate()
    
    # Definir caminhos de entrada e sa√≠da
    input_path = "s3://meu-bucket/dados/vendas.csv"
    output_path = "s3://meu-bucket/resultados/vendas_processadas"
    
    # Ler dados do CSV
    print("Lendo dados do S3...")
    df = spark.read.option("header", "true") \
                   .option("inferSchema", "true") \
                   .csv(input_path)
    
    print(f"Schema do DataFrame original:")
    df.printSchema()
    
    print(f"Total de registros: {df.count()}")
    
    # Realizar transforma√ß√µes
    print("Realizando transforma√ß√µes...")
    df_processado = df.withColumn("valor_com_imposto", col("valor") * 1.1) \
                      .withColumn("ano", year(col("data"))) \
                      .withColumn("mes", month(col("data"))) \
                      .withColumn("dia", dayofmonth(col("data")))
    
    # Mostrar alguns resultados
    print("Amostra dos dados processados:")
    df_processado.show(5)
    
    # Salvar resultados em formato Parquet
    print(f"Salvando resultados em {output_path}")
    df_processado.write.mode("overwrite") \
                       .partitionBy("ano", "mes") \
                       .parquet(output_path)
    
    print("Processamento conclu√≠do com sucesso!")
    
    # Encerrar a sess√£o Spark
    spark.stop()

if __name__ == "__main__":
    main()
```

![image](https://github.com/user-attachments/assets/56e3dc65-52d2-48aa-a2b6-8b2b0b5afb43)

‚û°Ô∏è Crie o arquivo processador_dados.py com o c√≥digo acima usando um editor como vscode ou vim.

### Passo 2: Fazer Upload do Script para o S3

Voc√™ pode fazer upload do script diretamente para o S3:

```bash
# Primeiro, crie o arquivo localmente no n√≥ master
nano processador_dados.py
# Cole o c√≥digo e salve (Ctrl+O, Enter, Ctrl+X)

# Depois, fa√ßa upload para o S3
aws s3 cp processador_dados.py s3://meu-bucket/scripts/
```

### Passo 3: Submeter a Aplica√ß√£o com Spark-Submit

Agora, vamos submeter a aplica√ß√£o ao cluster usando o comando `spark-submit`:

```bash
spark-submit \
  --master yarn \
  --deploy-mode cluster \
  --conf spark.yarn.submit.waitAppCompletion=true \
  --conf spark.sql.parquet.compression.codec=snappy \
  s3://meu-bucket/scripts/processador_dados.py
```


‚û°Ô∏è Execute o comando spark-submit conforme mostrado acima, substituindo o caminho do S3 pelo seu bucket.

üí° **Dica**: Use o par√¢metro `--conf spark.yarn.submit.waitAppCompletion=true` para que o comando `spark-submit` aguarde a conclus√£o da aplica√ß√£o antes de retornar.

## Explica√ß√£o Detalhada dos Par√¢metros

### `--master yarn`

Este par√¢metro especifica que o YARN ser√° usado como gerenciador de recursos. No EMR, o YARN √© o gerenciador padr√£o e recomendado.

### `--deploy-mode cluster`

No modo `cluster`, o driver da aplica√ß√£o Spark √© executado dentro do cluster YARN, em um dos n√≥s. Isso √© recomendado para aplica√ß√µes de produ√ß√£o, pois:

1. Se a conex√£o SSH cair, a aplica√ß√£o continua rodando
2. Os logs do driver ficam no cluster, n√£o no terminal local
3. O driver utiliza recursos do cluster, n√£o da m√°quina que submete o job

No modo `client` (padr√£o), o driver √© executado na m√°quina que submete o job, o que √© √∫til para desenvolvimento e debugging.


‚û°Ô∏è No modo client, o driver roda na m√°quina que submete o job. No modo cluster, o driver roda dentro do YARN.

### Configura√ß√µes Adicionais √öteis

Voc√™ pode adicionar v√°rias configura√ß√µes usando o par√¢metro `--conf`:

```bash
spark-submit \
  --master yarn \
  --deploy-mode cluster \
  --conf spark.executor.memory=4g \
  --conf spark.executor.cores=2 \
  --conf spark.executor.instances=10 \
  --conf spark.driver.memory=2g \
  --conf spark.sql.shuffle.partitions=200 \
  s3://meu-bucket/scripts/processador_dados.py
```

## Como Verificar Logs no EMR

Quando voc√™ executa uma aplica√ß√£o Spark no modo cluster, os logs n√£o s√£o exibidos diretamente no terminal. Voc√™ precisa acess√°-los atrav√©s do YARN ou do Spark History Server.

### Verificando Logs via YARN

1. Primeiro, liste as aplica√ß√µes YARN para obter o ID da aplica√ß√£o:

```bash
yarn application -list
```

Exemplo de sa√≠da:
```
Total number of applications (application-types: [] and states: [SUBMITTED, ACCEPTED, RUNNING]):1
                Application-Id      Application-Name        Application-Type          User           State         Final-State         Progress                       Tracking-URL
application_1621234567890_0001     Processador de Dados S3           SPARK        hadoop           RUNNING           UNDEFINED             10%                  http://ip-172-31-25-107.ec2.internal:8088/proxy/application_1621234567890_0001/
```

2. Visualize os logs da aplica√ß√£o:

```bash
yarn logs -applicationId application_1621234567890_0001
```

üí° **Dica**: Para ver apenas os logs do driver:

```bash
yarn logs -applicationId application_1621234567890_0001 -log_files stdout
```

### Verificando Logs via Interface Web

O EMR fornece interfaces web para monitorar aplica√ß√µes:

1. **ResourceManager UI**: http://MASTER_DNS:8088
2. **Spark History Server**: http://MASTER_DNS:18080

Para acessar essas interfaces, voc√™ precisa configurar um t√∫nel SSH:

```bash
ssh -i /caminho/para/MeuParDeChaves.pem -N -L 8088:localhost:8088 -L 18080:localhost:18080 hadoop@ec2-xx-xx-xx-xx.compute-1.amazonaws.com
```


‚û°Ô∏è Acesse http://localhost:8088 no seu navegador ap√≥s configurar o t√∫nel SSH.

## Monitorando o Progresso da Aplica√ß√£o

### Via Linha de Comando

```bash
# Verificar status da aplica√ß√£o
yarn application -status application_1621234567890_0001

# Listar cont√™ineres da aplica√ß√£o
yarn container -list application_1621234567890_0001
```

### Via Interface Web

Na interface do ResourceManager (http://localhost:8088), voc√™ pode:

1. Ver o status de todas as aplica√ß√µes
2. Acessar logs detalhados
3. Monitorar o uso de recursos
4. Matar aplica√ß√µes se necess√°rio


‚û°Ô∏è Clique no ID da aplica√ß√£o na interface do ResourceManager para ver detalhes.

## Exemplos Avan√ßados de Spark-Submit

### Exemplo com Argumentos de Linha de Comando

```python
# processador_com_args.py
from pyspark.sql import SparkSession
import sys

def main():
    if len(sys.argv) != 3:
        print("Uso: processador_com_args.py <input_path> <output_path>")
        sys.exit(1)
        
    input_path = sys.argv[1]
    output_path = sys.argv[2]
    
    spark = SparkSession.builder \
        .appName("Processador com Argumentos") \
        .getOrCreate()
    
    # Resto do c√≥digo...
    
if __name__ == "__main__":
    main()
```

Comando para executar:

```bash
spark-submit \
  --master yarn \
  --deploy-mode cluster \
  s3://meu-bucket/scripts/processador_com_args.py \
  s3://meu-bucket/dados/entrada.csv \
  s3://meu-bucket/resultados/saida
```

### Exemplo com Configura√ß√£o de Mem√≥ria e Cores

```bash
spark-submit \
  --master yarn \
  --deploy-mode cluster \
  --driver-memory 4g \
  --executor-memory 8g \
  --executor-cores 4 \
  --num-executors 5 \
  s3://meu-bucket/scripts/processador_dados.py
```

### Exemplo com Arquivos Python Adicionais

```bash
spark-submit \
  --master yarn \
  --deploy-mode cluster \
  --py-files s3://meu-bucket/scripts/utils.py,s3://meu-bucket/scripts/transformacoes.py \
  s3://meu-bucket/scripts/processador_dados.py
```

## Boas Pr√°ticas para Spark-Submit üî•

1. **Modo de Implanta√ß√£o**: Use `--deploy-mode cluster` para aplica√ß√µes de produ√ß√£o.

2. **Gerenciamento de Recursos**: Ajuste `--executor-memory`, `--executor-cores` e `--num-executors` com base no tamanho do cluster e dos dados.

3. **Particionamento**: Configure `spark.sql.shuffle.partitions` para otimizar o desempenho (regra geral: 2-3x o n√∫mero total de cores no cluster).

4. **Compress√£o**: Use `spark.sql.parquet.compression.codec=snappy` para um bom equil√≠brio entre compress√£o e velocidade.

5. **Logs**: Ative logs detalhados com `spark.eventLog.enabled=true` para melhor monitoramento.

6. **Tratamento de Erros**: Implemente tratamento de exce√ß√µes robusto em seus scripts Python.

7. **Checkpointing**: Para jobs longos, considere usar checkpointing para recupera√ß√£o de falhas:
   ```python
   spark.sparkContext.setCheckpointDir("s3://meu-bucket/checkpoints")
   df.checkpoint()
   ```

## Solu√ß√£o de Problemas Comuns

### Erro "No such file or directory"

Verifique:
- Se o caminho do S3 est√° correto
- Se as permiss√µes IAM permitem acesso ao bucket
- Se o script foi carregado corretamente para o S3

### Erro "Container killed by YARN"

Poss√≠veis solu√ß√µes:
- Aumente a mem√≥ria do executor (`--executor-memory`)
- Reduza o paralelismo ou o n√∫mero de parti√ß√µes
- Verifique se h√° transforma√ß√µes que consomem muita mem√≥ria (como `groupBy` ou `join`)

### Aplica√ß√£o Lenta

Verifique:
- N√∫mero de parti√ß√µes (muito poucas ou muitas)
- Skew nos dados (distribui√ß√£o desigual)
- Opera√ß√µes de shuffle excessivas
- Configura√ß√µes de mem√≥ria e cores inadequadas

## Conclus√£o

Neste cap√≠tulo, voc√™ aprendeu a estrutura b√°sica do comando `spark-submit`, como executar aplica√ß√µes Python que processam dados no S3 e como monitorar o progresso e verificar logs no EMR. No pr√≥ximo cap√≠tulo, aprenderemos como empacotar seu c√≥digo Python em um arquivo wheel (.whl) para facilitar a distribui√ß√£o e execu√ß√£o no cluster.

---

üîç **Pr√≥ximo Cap√≠tulo**: [Criando e Subindo Wheel no VS Code](04_criando_e_subindo_wheel_vs_code.md)
