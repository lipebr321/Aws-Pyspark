# Cap√≠tulo 5: Rodando Spark com Wheel no S3

## Introdu√ß√£o

Ap√≥s criar e fazer upload do seu pacote wheel para o S3, o pr√≥ximo passo √© execut√°-lo no cluster EMR. Neste cap√≠tulo, voc√™ aprender√° como submeter jobs Spark que utilizam seu pacote wheel, monitorar a execu√ß√£o e validar os resultados. Esta abordagem permite que voc√™ execute c√≥digo Python modular e bem organizado em um ambiente distribu√≠do.

## Pr√©-requisitos

Antes de come√ßar, voc√™ precisar√°:

- Um cluster EMR em execu√ß√£o
- Um arquivo wheel (.whl) armazenado no S3
- Acesso SSH ao n√≥ master do cluster
- Conhecimentos b√°sicos de PySpark e EMR

## Gloss√°rio para Iniciantes üìù

- **Wheel (.whl)**: Formato de pacote Python pr√©-compilado
- **py-files**: Par√¢metro do spark-submit para incluir arquivos Python ou zips no PYTHONPATH
- **PYTHONPATH**: Vari√°vel de ambiente que define onde o Python procura m√≥dulos
- **Driver Program**: Processo principal que coordena a execu√ß√£o da aplica√ß√£o Spark
- **Executor**: Processo que executa as tarefas da aplica√ß√£o Spark
- **YARN**: Gerenciador de recursos do Hadoop que aloca recursos para aplica√ß√µes
- **ApplicationMaster**: Processo YARN que gerencia a aplica√ß√£o no cluster

## Executando o Wheel Diretamente no Cluster EMR

### Passo 1: Verificar se o Wheel est√° Dispon√≠vel no S3

Antes de executar o job, verifique se o arquivo wheel est√° acess√≠vel no S3:

```bash
aws s3 ls s3://meu-bucket/wheels/meu_pacote_spark-0.1.0-py3-none-any.whl
```

üñºÔ∏è **Print do terminal mostrando o resultado do comando aws s3 ls**
‚û°Ô∏è Execute o comando para verificar se o arquivo wheel est√° dispon√≠vel no S3.

### Passo 2: Preparar o Script Principal

Voc√™ pode criar um script simples que importa e utiliza as fun√ß√µes do seu pacote. Este script ser√° o ponto de entrada para o spark-submit:

```python
# main.py
import argparse
import logging
from pyspark.sql import SparkSession

# Importar fun√ß√µes do nosso pacote wheel
from meu_pacote.utils import criar_spark_session, ler_dados_csv, salvar_como_parquet
from meu_pacote.transformacoes import transformar_colunas_texto, extrair_componentes_data
from meu_pacote.validacoes import validar_valores_nulos

def main():
    # Configurar argumentos da linha de comando
    parser = argparse.ArgumentParser(description='Processador de dados com wheel')
    parser.add_argument('--input', required=True, help='Caminho de entrada dos dados (S3)')
    parser.add_argument('--output', required=True, help='Caminho de sa√≠da para os resultados (S3)')
    args = parser.parse_args()
    
    # Configurar logging
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
    logger = logging.getLogger(__name__)
    
    logger.info(f"Iniciando processamento: entrada={args.input}, sa√≠da={args.output}")
    
    # Criar sess√£o Spark
    spark = criar_spark_session("Aplica√ß√£o com Wheel")
    
    try:
        # Ler dados
        df = ler_dados_csv(spark, args.input)
        logger.info(f"Dados carregados: {df.count()} registros")
        
        # Aplicar transforma√ß√µes
        df = transformar_colunas_texto(df, ["produto", "categoria"])
        df = extrair_componentes_data(df, "data_venda")
        
        # Verificar valores nulos
        nulos = validar_valores_nulos(df, ["produto", "valor"])
        for coluna, contagem in nulos.items():
            logger.info(f"Coluna {coluna}: {contagem} valores nulos")
        
        # Salvar resultados
        salvar_como_parquet(df, args.output, particionar_por=["ano", "mes"])
        logger.info(f"Processamento conclu√≠do com sucesso!")
        
    except Exception as e:
        logger.error(f"Erro durante o processamento: {str(e)}")
        raise
    finally:
        spark.stop()

if __name__ == "__main__":
    main()
```

Fa√ßa upload deste script para o S3:

```bash
aws s3 cp main.py s3://meu-bucket/scripts/
```

### Passo 3: Executar o Job com Spark-Submit

Agora, vamos executar o job usando o comando `spark-submit` com o par√¢metro `--py-files` para incluir o wheel:

```bash
spark-submit \
  --master yarn \
  --deploy-mode cluster \
  --py-files s3://meu-bucket/wheels/meu_pacote_spark-0.1.0-py3-none-any.whl \
  s3://meu-bucket/scripts/main.py \
  --input s3://meu-bucket/dados/vendas.csv \
  --output s3://meu-bucket/resultados/vendas_processadas
```

üñºÔ∏è **Print do terminal executando o comando spark-submit**
‚û°Ô∏è Execute o comando spark-submit conforme mostrado acima, substituindo os caminhos do S3 pelos seus.

üí° **Dica**: O par√¢metro `--py-files` pode receber m√∫ltiplos arquivos separados por v√≠rgula, incluindo arquivos .py, .zip ou .whl.

## C√≥digo Pronto para Spark-Submit Utilizando --py-files

Vamos ver alguns exemplos mais avan√ßados de como utilizar o par√¢metro `--py-files` com diferentes configura√ß√µes:

### Exemplo 1: Configura√ß√£o B√°sica

```bash
spark-submit \
  --master yarn \
  --deploy-mode cluster \
  --py-files s3://meu-bucket/wheels/meu_pacote_spark-0.1.0-py3-none-any.whl \
  s3://meu-bucket/scripts/main.py \
  --input s3://meu-bucket/dados/vendas.csv \
  --output s3://meu-bucket/resultados/vendas_processadas
```

### Exemplo 2: Com Configura√ß√µes de Recursos

```bash
spark-submit \
  --master yarn \
  --deploy-mode cluster \
  --executor-memory 4g \
  --executor-cores 2 \
  --num-executors 10 \
  --driver-memory 2g \
  --conf spark.yarn.submit.waitAppCompletion=true \
  --py-files s3://meu-bucket/wheels/meu_pacote_spark-0.1.0-py3-none-any.whl \
  s3://meu-bucket/scripts/main.py \
  --input s3://meu-bucket/dados/vendas.csv \
  --output s3://meu-bucket/resultados/vendas_processadas
```

### Exemplo 3: Com M√∫ltiplos Arquivos Python

```bash
spark-submit \
  --master yarn \
  --deploy-mode cluster \
  --py-files s3://meu-bucket/wheels/meu_pacote_spark-0.1.0-py3-none-any.whl,s3://meu-bucket/scripts/utils_adicionais.py \
  s3://meu-bucket/scripts/main.py \
  --input s3://meu-bucket/dados/vendas.csv \
  --output s3://meu-bucket/resultados/vendas_processadas
```

### Exemplo 4: Com Configura√ß√µes de Log e Checkpoint

```bash
spark-submit \
  --master yarn \
  --deploy-mode cluster \
  --conf spark.eventLog.enabled=true \
  --conf spark.eventLog.dir=s3://meu-bucket/spark-logs \
  --conf spark.yarn.maxAppAttempts=2 \
  --py-files s3://meu-bucket/wheels/meu_pacote_spark-0.1.0-py3-none-any.whl \
  s3://meu-bucket/scripts/main.py \
  --input s3://meu-bucket/dados/vendas.csv \
  --output s3://meu-bucket/resultados/vendas_processadas
```

## Monitorando o Progresso da Tarefa

### Via Linha de Comando

Ap√≥s submeter o job, voc√™ pode monitorar seu progresso usando comandos YARN:

```bash
# Listar aplica√ß√µes em execu√ß√£o
yarn application -list

# Verificar status de uma aplica√ß√£o espec√≠fica
yarn application -status application_1621234567890_0001

# Ver logs da aplica√ß√£o
yarn logs -applicationId application_1621234567890_0001
```

üñºÔ∏è **Print do terminal mostrando o resultado do comando yarn application -list**
‚û°Ô∏è Execute o comando para listar as aplica√ß√µes em execu√ß√£o no YARN.

### Via Interface Web

Voc√™ tamb√©m pode monitorar o progresso atrav√©s das interfaces web do EMR:

1. **ResourceManager UI**: http://MASTER_DNS:8088
2. **Spark History Server**: http://MASTER_DNS:18080

Para acessar essas interfaces, configure um t√∫nel SSH:

```bash
ssh -i /caminho/para/MeuParDeChaves.pem -N -L 8088:localhost:8088 -L 18080:localhost:18080 hadoop@ec2-xx-xx-xx-xx.compute-1.amazonaws.com
```

üñºÔ∏è **Print da interface web do YARN ResourceManager**
‚û°Ô∏è Acesse http://localhost:8088 no seu navegador ap√≥s configurar o t√∫nel SSH.

## Validando o Resultado dos Dados Processados

Ap√≥s a conclus√£o do job, √© importante validar se os dados foram processados corretamente:

### Passo 1: Verificar se os Arquivos Foram Criados no S3

```bash
aws s3 ls s3://meu-bucket/resultados/vendas_processadas/
```

### Passo 2: Verificar a Estrutura de Particionamento

```bash
aws s3 ls s3://meu-bucket/resultados/vendas_processadas/ano=2023/mes=1/
```

### Passo 3: Examinar os Dados com Spark

Voc√™ pode criar um script simples para ler e validar os dados processados:

```python
# validar_resultados.py
from pyspark.sql import SparkSession

# Inicializar a sess√£o Spark
spark = SparkSession.builder \
    .appName("Valida√ß√£o de Resultados") \
    .getOrCreate()

# Ler os dados processados
df = spark.read.parquet("s3://meu-bucket/resultados/vendas_processadas/")

# Mostrar o schema
print("Schema dos dados processados:")
df.printSchema()

# Contar registros
total_registros = df.count()
print(f"Total de registros: {total_registros}")

# Verificar parti√ß√µes
print("Distribui√ß√£o por ano e m√™s:")
df.groupBy("ano", "mes").count().orderBy("ano", "mes").show()

# Verificar estat√≠sticas b√°sicas
print("Estat√≠sticas de valores:")
df.select("valor", "valor_com_imposto").describe().show()

# Encerrar a sess√£o Spark
spark.stop()
```

Execute este script localmente no n√≥ master:

```bash
spark-submit validar_resultados.py
```

## Boas Pr√°ticas para Execu√ß√£o de Jobs com Wheels üî•

1. **Versionamento**: Inclua a vers√£o no nome do arquivo wheel para facilitar o controle de vers√µes.

2. **Logs Detalhados**: Implemente logging detalhado em seu c√≥digo para facilitar a depura√ß√£o.

3. **Tratamento de Erros**: Implemente tratamento de exce√ß√µes robusto para falhas previs√≠veis.

4. **Checkpointing**: Para jobs longos, use checkpointing para permitir recupera√ß√£o em caso de falhas:
   ```python
   spark.sparkContext.setCheckpointDir("s3://meu-bucket/checkpoints")
   df.checkpoint()
   ```

5. **Configura√ß√£o de Recursos**: Ajuste os par√¢metros de mem√≥ria e cores com base no tamanho dos dados:
   ```bash
   --executor-memory 4g --executor-cores 2 --num-executors 10
   ```

6. **Monitoramento**: Configure alertas e monitoramento para jobs cr√≠ticos.

7. **Testes**: Teste seu c√≥digo com conjuntos de dados menores antes de executar em produ√ß√£o.

8. **Documenta√ß√£o**: Mantenha documenta√ß√£o atualizada sobre como executar seus jobs.

## Solu√ß√£o de Problemas Comuns

### Erro "No module named 'meu_pacote'"

Verifique:
- Se o caminho do wheel no par√¢metro `--py-files` est√° correto
- Se o wheel foi criado corretamente
- Se o wheel est√° acess√≠vel no S3

### Erro "Container killed by YARN"

Poss√≠veis solu√ß√µes:
- Aumente a mem√≥ria do executor (`--executor-memory`)
- Reduza o paralelismo ou o n√∫mero de parti√ß√µes
- Verifique se h√° transforma√ß√µes que consomem muita mem√≥ria

### Job Lento ou Travado

Verifique:
- N√∫mero de parti√ß√µes (muito poucas ou muitas)
- Skew nos dados (distribui√ß√£o desigual)
- Opera√ß√µes de shuffle excessivas
- Configura√ß√µes de mem√≥ria e cores inadequadas

### Erro ao Acessar Arquivos no S3

Verifique:
- Permiss√µes IAM do cluster
- Se o bucket e os objetos existem
- Se o formato do caminho S3 est√° correto

## Conclus√£o

Neste cap√≠tulo, voc√™ aprendeu como executar aplica√ß√µes Spark que utilizam pacotes wheel armazenados no S3, monitorar o progresso da execu√ß√£o e validar os resultados. Esta abordagem permite que voc√™ desenvolva c√≥digo Python modular e bem organizado, facilitando a manuten√ß√£o e reutiliza√ß√£o. No pr√≥ximo cap√≠tulo, aprenderemos como clonar um cluster EMR para reutilizar configura√ß√µes.

---

üîç **Pr√≥ximo Cap√≠tulo**: [Clonando Cluster EMR](06_clonando_cluster_emr.md)
